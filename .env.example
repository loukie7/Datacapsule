本项目使用DSPy进行意图识别，需要配置两个独立的模型：
Dspy官方中文文档信息：https://www.aidoczh.com/dspy/
1. 问答/推理模型：用于处理用户查询和推理任务
2. 后训练模型：用于基于用户的业务问答得到的反馈数据，进行后训练任务
两个模型可以使用相同或不同的配置，支持OpenAI-SDK格式的模型：
- OpenAI API系列：GPT-3.5/4
- DeepSeek系列：deepseek-chat/coder
- 阿里云系列：Qwen/通义千问
- 百度文心系列：ERNIE-Bot
- Ollama本地部署
- HuggingFace部署
- VLLM高性能部署


# 问答/推理模型配置（用于处理用户查询和推理）
LLM_TYPE ="deepseek"                # 模型类型
API_KEY ="sk-you_api_key"             # API密钥
BASE_URL ="https://api.deepseek.com/v1"  # API基础地址
LLM_MODEL ="deepseek-chat"          # 具体的模型名称

# Ollama配置（本地部署方案，适合离线环境）
# LLM_TYPE="ollama_chat"           # 设置为使用Ollama本地模型
# API_KEY=""                       # Ollama本地部署不需要API密钥
# BASE_URL="http://localhost:11434" # Ollama服务的本地地址
# LLM_MODEL="gemma3:12b"           # 使用的具体模型，这里使用Gemma 12B版本

# 后训练模型配置（用于模型训练和知识提取,可以和问答/推理模型配置相同，也可以用更适合的模型）
Train_LLM_TYPE ="deepseek"            # 后训练模型类型
Train_LLM_MODEL ="deepseek-chat" # 后训练使用的具体模型
Train_OPENAI_API_KEY ="sk-you_api_key"  # 后训练模型的API密钥
Train_OPENAI_BASE_URL ="https://api.deepseek.com/v1"  # 后训练模型的API地址

# 系统环境配置（核心路径和基础设置）
RAG_DIR = "graph_data_new"         # 知识图谱数据的存储目录
LOG_LEVEL = "DEBUG"                # 日志级别，可选：DEBUG, INFO, WARNING, ERROR
DATABASE_URL ="sqlite:///.dbs/interactions.db"  # 用户交互记录数据库的路径
SPECIES_DB_URL = "./.dbs/marine_species.db"    # 物种信息数据库的路径

# 向量检索配置（影响检索质量和效率的关键参数）
VECTOR_SEARCH_TOP_K = 3            # 向量检索返回的最大结果数量
BETTER_THAN_THRESHOLD = 0.7        # 相似度筛选阈值，范围0-1，越大要求越严格
GRAPHML_DIR = "graph_entity_relation_detailed.graphml"  # 知识图谱的存储文件路径

# Embedding配置（文本向量化相关参数）
MAX_BATCH_SIZE = 100               # 批处理大小，影响处理速度和内存使用
EMBEDDING_MAX_TOKEN_SIZE = 8192    # 单次能处理的最大token数量
EMBEDDING_DIM = 1024              # 生成的向量维度
EMBEDDING_MODEL = "text-embedding-v3"  # 使用的embedding模型版本
EMBEDDING_MODEL_BASE_URL ="https://dashscope.Trainyuncs.com/compatible-mode/v1"  # embedding服务的API地址
EMBEDDING_MODEL_API_KEY ="sk-you_api_key"  # embedding服务的API密钥

# 检索相关配置
MAX_ITERS = 10           # 最大检索迭代次数，控制循环次数，官方默认是 5 次
